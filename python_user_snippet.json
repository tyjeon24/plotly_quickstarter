{
	"기본 코드":{
		"prefix":"plotly_1_basic_user_code_snippet",
		"body":[
				"from plotly.subplots import make_subplots",
				"import plotly.graph_objects as go",
				"",
				"fig = make_subplots(rows=3, cols=1,shared_xaxes=True,vertical_spacing=0.02)",
				"fig.add_trace(go.Scatter(x=[0, 1, 2], y=[10, 11, 12], name='PLOT 1'),row=3, col=1)",
				"fig.add_trace(go.Scatter(x=[2, 3, 4], y=[100, 110, 120], name='PLOT 2'),row=2, col=1)",
				"fig.add_trace(go.Scatter(x=[3, 4, 5], y=[1000, 1100, 1200], name='PLOT 3'),row=1, col=1)",
				"fig.update_layout(height=600, width=600,title_text='Stacked Subplots with Shared X-Axes', title_x=0.5)",
				"fig.show()",
				"import plotly.graph_objects as go",
				"from plotly.subplots import make_subplots",
				"",
				"fig = make_subplots(specs=[[{'secondary_y': True}]])",
				"fig.add_trace(go.Scatter(x=[1, 2, 3], y=[40, 50, 60], name='왼쪽'),secondary_y=False)",
				"fig.add_trace(go.Scatter(x=[2, 3, 4], y=[4, 5, 6], name='오른쪽'),secondary_y=True)",
				"fig.update_layout(title_text='제목', title_x=0.5)",
				"fig.update_xaxes(title_text='X축 제목')",
				"fig.update_yaxes(title_text='&lt;b&gt;왼쪽 제목&lt;/b&gt;', secondary_y=False)",
				"fig.update_yaxes(title_text='오른쪽 제목', secondary_y=True)",
				"fig.show()"
		]
	},
	"콜백+부트스트랩":{
		"prefix":"dash_1_basic_user_code_snippet",
		"body":[
				"import dash",
				"import dash_bootstrap_components as dbc",
				"from dash import Input, Output, html",
				"",
				"white_button_style = {'background-color': 'white', 'color': 'black'}",
				"red_button_style = {'background-color': 'red', 'color': 'white'}",
				"",
				"app = dash.Dash(external_stylesheets=[dbc.themes.DARKLY])",
				"click_counter_button = dbc.Button('Click me', className='me-2', n_clicks=0)",
				"app.layout = html.Div([click_counter_button, number_of_click_text := html.Span()])",
				"",
				"",
				"@app.callback(",
				"    [Output(number_of_click_text, 'children'),",
				"     Output(click_counter_button, 'children'),",
				"     Output(click_counter_button, 'style')],",
				"    [Input(click_counter_button, 'n_clicks')],",
				")",
				"def on_button_click(n):",
				"    style = red_button_style",
				"    if n % 2 == 0:",
				"        style = white_button_style",
				"    return f'Clicked {n} times.', n, style",
				"",
				"",
				"if __name__ == '__main__':",
				"    app.run_server()"
		]
	},
	"애니메이션":{
		"prefix":"dash_2_animation_user_code_snippet",
		"body":[
				"from dash import Dash, dcc, html, Input, Output, clientside_callback, State",
				"import pandas as pd",
				"import numpy as np",
				"",
				"df = pd.DataFrame({",
				"    'x' : [i for i in range(10000)],",
				"    'phase_1' : [np.sin(4*np.pi*i*0.01) for i in range(10000)],",
				"    'phase_2' : [np.sin(4*np.pi*i*0.01 - 2*(np.pi)/3) for i in range(10000)],",
				"    'phase_3' : [np.sin(4*np.pi*i*0.01 - (np.pi)/3) for i in range(10000)],",
				"})",
				"",
				"app = Dash(__name__)",
				"app.layout = html.Div([",
				"    dcc.Graph(id='clientside-graph'),",
				"    dcc.Interval(id='interval', interval=25),",
				"    dcc.Store(id='sin_wave',data=df.to_dict('list'))",
				"])",
				"",
				"clientside_callback(",
				"    '''",
				"    function(n_intervals, data) {",
				"            return [{",
				"            'data':[",
				"                        {",
				"                            'x':data['x'].slice(0,n_intervals),",
				"                            'y':data['phase_1'].slice(0,n_intervals)",
				"                        },",
				"                        {",
				"                            'x':data['x'].slice(0,n_intervals),",
				"                            'y':data['phase_2'].slice(0,n_intervals)",
				"                        },",
				"                        {",
				"                            'x':data['x'].slice(0,n_intervals),",
				"                            'y':data['phase_3'].slice(0,n_intervals)",
				"                        }",
				"                    ]",
				"                },",
				"            ];",
				"        }",
				"    ''',",
				"    [Output('clientside-graph', 'figure')],",
				"    [Input('interval', 'n_intervals')],",
				"    [State('sin_wave', 'data')],",
				")",
				"",
				"if __name__ == '__main__':",
				"    app.run(debug=True)"
		]
	},
	"비동기 요청":{
		"prefix":"async_1_requests_user_code_snippet",
		"body":[
			"# https://www.twilio.com/blog/asynchronous-http-requests-in-python-with-aiohttp",
			"import aiohttp",
			"import asyncio",
			"import sys",
			"import time",
			"",
			"if USING_NOTEBOOK:='ipykernel' in sys.modules:",
			"    import nest_asyncio",
			"    nest_asyncio.apply()",
			"",
			"start = time.time()",
			"",
			"async def get_info(session, url):",
			"    async with session.get(url) as resp:",
			"        response = await resp.json()",
			"        data = response['name']",
			"        return data",
			"",
			"async def main():",
			"    async with aiohttp.ClientSession() as session:",
			"        tasks = [asyncio.ensure_future(get_info(session, f'https://pokeapi.co/api/v2/pokemon/{number}')) for number in range(1, 151)]",
			"        result = await asyncio.gather(*tasks)",
			"    return result",
			"",
			"result = asyncio.run(main())",
			"print(result)",
			"print(time.time() - start)"
		]
	},
	
	"opencv_1_color_selector_user_code_snippet":{
		"prefix":"opencv_1_color_selector_user_code_snippet",
		"body":[
				"# https://stackoverflow.com/a/57469788",
				"import cv2",
				"import sys",
				"import numpy as np",
				"",
				"def nothing(x):",
				"    pass",
				"",
				"# Create a window",
				"cv2.namedWindow('image')",
				"",
				"# create trackbars for color change",
				"cv2.createTrackbar('HMin','image',0,179,nothing) # Hue is from 0-179 for Opencv",
				"cv2.createTrackbar('SMin','image',0,255,nothing)",
				"cv2.createTrackbar('VMin','image',0,255,nothing)",
				"cv2.createTrackbar('HMax','image',0,179,nothing)",
				"cv2.createTrackbar('SMax','image',0,255,nothing)",
				"cv2.createTrackbar('VMax','image',0,255,nothing)",
				"",
				"# Set default value for MAX HSV trackbars.",
				"cv2.setTrackbarPos('HMax', 'image', 179)",
				"cv2.setTrackbarPos('SMax', 'image', 255)",
				"cv2.setTrackbarPos('VMax', 'image', 255)",
				"",
				"# Initialize to check if HSV min/max value changes",
				"hMin = sMin = vMin = hMax = sMax = vMax = 0",
				"phMin = psMin = pvMin = phMax = psMax = pvMax = 0",
				"",
				"img = cv2.imread('D:\/untitled.png')",
				"output = img",
				"waitTime = 33",
				"",
				"while(1):",
				"",
				"    # get current positions of all trackbars",
				"    hMin = cv2.getTrackbarPos('HMin','image')",
				"    sMin = cv2.getTrackbarPos('SMin','image')",
				"    vMin = cv2.getTrackbarPos('VMin','image')",
				"",
				"    hMax = cv2.getTrackbarPos('HMax','image')",
				"    sMax = cv2.getTrackbarPos('SMax','image')",
				"    vMax = cv2.getTrackbarPos('VMax','image')",
				"",
				"    # Set minimum and max HSV values to display",
				"    lower = np.array([hMin, sMin, vMin])",
				"    upper = np.array([hMax, sMax, vMax])",
				"",
				"    # Create HSV Image and threshold into a range.",
				"    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)",
				"    mask = cv2.inRange(hsv, lower, upper)",
				"    output = cv2.bitwise_and(img,img, mask= mask)",
				"",
				"    # Print if there is a change in HSV value",
				"    if( (phMin != hMin) | (psMin != sMin) | (pvMin != vMin) | (phMax != hMax) | (psMax != sMax) | (pvMax != vMax) ):",
				"        print('(hMin = %d , sMin = %d, vMin = %d), (hMax = %d , sMax = %d, vMax = %d)' % (hMin , sMin , vMin, hMax, sMax , vMax))",
				"        phMin = hMin",
				"        psMin = sMin",
				"        pvMin = vMin",
				"        phMax = hMax",
				"        psMax = sMax",
				"        pvMax = vMax",
				"",
				"    # Display output image",
				"    cv2.imshow('image',output)",
				"",
				"    # Wait longer to prevent freeze for videos.",
				"    if cv2.waitKey(waitTime) & 0xFF == ord('q'):",
				"        break",
				"",
				"cv2.destroyAllWindows()"
		],
		"description":"색 범위 지정 기능입니다."
	},
	"pytorch_1_regression_user_code_snippet":{
		"prefix":"pytorch_1_regression_user_code_snippet",
		"body":[
				"# %%",
				"# 패키지 불러오기",
				"import torch",
				"import torch.nn as nn",
				"from torch.utils.data import Dataset, DataLoader",
				"from sklearn.model_selection import train_test_split",
				"",
				"",
				"# 데이터셋",
				"class MyDataset(Dataset):",
				"    def __init__(self, X, y):",
				"        self.X = X",
				"        self.y = y",
				"",
				"    def __len__(self):",
				"        return len(self.X)",
				"",
				"    def __getitem__(self, idx):",
				"        return self.X[idx], self.y[idx]",
				"",
				"",
				"# 훈련 메서드",
				"def train(model, X_train, y_train, loss_function):",
				"    train_loader = DataLoader(",
				"        dataset=MyDataset(X_train, y_train), batch_size=BATCH_SIZE",
				"    )",
				"    optimizer = torch.optim.Adam(model.parameters())",
				"    for epoch in range(EPOCHS):",
				"        for X, y in train_loader:",
				"            optimizer.zero_grad()",
				"            loss = loss_function(model(X), y)",
				"            loss.backward()",
				"            optimizer.step()",
				"",
				"        # print loss",
				"        if epoch % 100 == 0:",
				"            print(f'Epoch {epoch}, Loss: {loss.data}')",
				"    return model",
				"",
				"",
				"# 이 위까지는 공통 활용 코드로 수정 불필요",
				"###########################################################################################",
				"# %%",
				"# 하이퍼파라미터",
				"LEARNING_RATE = 0.02",
				"BATCH_SIZE = 2",
				"HIDDEN_FEATURES = 20",
				"EPOCHS = 200",
				"",
				"# %%",
				"# 데이터 준비",
				"from sklearn.datasets import make_regression",
				"",
				"X, y = make_regression(n_samples=200, n_features=5, noise=1, random_state=42)",
				"X = torch.FloatTensor(X)",
				"y = torch.FloatTensor(y.reshape(-1, 1))  # y.shape = (200,) 에서 (200, 1) 형태의 2차원 배열로 변경",
				"",
				"",
				"# %%",
				"# 모델 선언",
				"class RegressionNetwork(nn.Module):",
				"    def __init__(self, input_features, hidden_features, output_features):",
				"        super(RegressionNetwork, self).__init__()",
				"        self.linear = nn.Linear(input_features, hidden_features)",
				"        self.linear_2 = nn.Linear(hidden_features, output_features)",
				"",
				"    def forward(self, x):",
				"        x = self.linear(x)",
				"        x = self.linear_2(x)",
				"        return x",
				"",
				"",
				"model = RegressionNetwork(",
				"    input_features=X.shape[1] if len(X.shape) != 1 else 1,",
				"    hidden_features=HIDDEN_FEATURES,",
				"    output_features=y.shape[1] if len(y.shape) != 1 else 1,",
				")",
				"",
				"# %%",
				"# 학습",
				"X_train, X_test, y_train, y_test = train_test_split(X, y)",
				"loss_function = nn.MSELoss()",
				"model = train(",
				"    model,",
				"    X_train,",
				"    y_train,",
				"    loss_function",
				")",
				"",
				"# %%",
				"# 모델 저장 및 불러오기",
				"torch.save(model.state_dict(), 'my_model.pth')",
				"model = RegressionNetwork(",
				"    input_features=X.shape[1] if len(X.shape) != 1 else 1,",
				"    hidden_features=HIDDEN_FEATURES,",
				"    output_features=y.shape[1] if len(y.shape) != 1 else 1,",
				")",
				"model.load_state_dict(torch.load('my_model.pth'))",
				"",
				"# %%",
				"# 예측",
				"from sklearn.metrics import r2_score",
				"",
				"with torch.no_grad():",
				"    y_pred = model(X_test)",
				"    score = r2_score(y_test, y_pred)",
				"    print(f'Test score{r2_score}: {score * 100}%')"
		],
		"description":"파이토치 기본 코드입니다."
	},
	"logging_1_log_basic_user_code_snippet":{
		"prefix":"logging_1_log_basic_user_code_snippet",
		"body":[
				"# https://hwangheek.github.io/2019/python-logging/",
				"import logging",
				"",
				"def get_config(filename='log'):",
				"    logger_config = {",
				"        'version': 1,",
				"        'disable_existing_loggers': False,",
				"        'formatters': {",
				"            'basic': {'format': '%(asctime)s - %(name)s - %(levelname)8s - %(message)s'}",
				"        },",
				"        'handlers': {",
				"            'console': {",
				"                'class': 'logging.StreamHandler',",
				"                'level': 'DEBUG',",
				"                'formatter': 'basic',",
				"            },",
				"            'file_debug': {",
				"                'class': 'logging.FileHandler',",
				"                'level': 'DEBUG',",
				"                'formatter': 'basic',",
				"                'filename': f'{filename}_debug.log',",
				"            },",
				"            'file_error': {",
				"                'class': 'logging.FileHandler',",
				"                'level': 'ERROR',",
				"                'formatter': 'basic',",
				"                'filename': f'{filename}_error.log',",
				"            },",
				"        },",
				"        'loggers': {",
				"            '__main__': {",
				"                'level': 'DEBUG',",
				"                'handlers': ['console', 'file_debug', 'file_error'],",
				"                'propagate': True,",
				"            }",
				"        },",
				"    }",
				"    return logger_config",
				"",
				"logger_name = 'log'",
				"logging.config.dictConfig(get_config(logger_name))",
				"logger = logging.getLogger(__name__)",
				"logger.debug('1. debug level log')",
				"logger.info('2. info level log')",
				"logger.warning('3. warning level log')",
				"logger.error('4. error level log')",
				"logger.critical('5. critical level log')"
		],
		"description":"로깅 기본 코드입니다."
	},
	"pytorch_2_classification_basic_user_code_snippet":{
		"prefix":"pytorch_2_classification_basic_user_code_snippet",
		"body":[
				"# %%",
				"# 패키지 불러오기",
				"import torch",
				"import torch.nn as nn",
				"from torch.utils.data import Dataset, DataLoader",
				"from sklearn.model_selection import train_test_split",
				"",
				"",
				"# 데이터셋",
				"class MyDataset(Dataset):",
				"    def __init__(self, X, y):",
				"        self.X = X",
				"        self.y = y",
				"",
				"    def __len__(self):",
				"        return len(self.X)",
				"",
				"    def __getitem__(self, idx):",
				"        return self.X[idx], self.y[idx]",
				"",
				"",
				"# 훈련 메서드",
				"def train(model, X_train, y_train, loss_function):",
				"    train_loader = DataLoader(",
				"        dataset=MyDataset(X_train, y_train), batch_size=BATCH_SIZE",
				"    )",
				"    optimizer = torch.optim.Adam(model.parameters())",
				"    for epoch in range(EPOCHS):",
				"        for X, y in train_loader:",
				"            optimizer.zero_grad()",
				"            loss = loss_function(model(X), y)",
				"            loss.backward()",
				"            optimizer.step()",
				"",
				"        # print loss",
				"        if epoch % 100 == 0:",
				"            print(f'Epoch {epoch}, Loss: {loss.data}')",
				"    return model",
				"",
				"",
				"# 이 위까지는 공통 활용 코드로 수정 불필요",
				"###########################################################################################",
				"# %%",
				"# 하이퍼파라미터",
				"BATCH_SIZE = 32",
				"HIDDEN_FEATURES = 6",
				"LEARNING_RATE = 0.02",
				"EPOCHS = 100",
				"",
				"# %%",
				"# 데이터 준비",
				"# y값 : nn.CrossEntropyLoss에 적용하려면 y.shape가 (N, )처럼 1차원 리스트여야 함. 2차원이면 안 됨.",
				"# y값 : LongTensor 타입이여야 손실 함수 연산 가능.",
				"from sklearn.datasets import load_iris",
				"",
				"iris = load_iris()",
				"X = torch.FloatTensor(iris.data)",
				"y = torch.LongTensor(iris.target)",
				"X_train, X_test, y_train, y_test = train_test_split(X, y)",
				"",
				"",
				"# %%",
				"# 모델 선언",
				"class MultiClassNetwork(nn.Module):",
				"    def __init__(self, NUM_FEATURES, NUM_CLASSES, HIDDEN_FEATURES):",
				"        super().__init__()",
				"        self.lin1 = nn.Linear(NUM_FEATURES, HIDDEN_FEATURES)",
				"        self.lin2 = nn.Linear(HIDDEN_FEATURES, NUM_CLASSES)",
				"        self.log_softmax = nn.LogSoftmax(dim=1)",
				"",
				"    def forward(self, x):",
				"        x = self.lin1(x)",
				"        x = torch.sigmoid(x)",
				"        x = self.lin2(x)",
				"        x = self.log_softmax(x)",
				"        return x",
				"",
				"",
				"model = MultiClassNetwork(",
				"    NUM_FEATURES=X.shape[1] if len(X.shape) != 1 else 1,",
				"    NUM_CLASSES=len(torch.unique(y)),",
				"    HIDDEN_FEATURES=HIDDEN_FEATURES,",
				")",
				"",
				"# %%",
				"# 학습",
				"train(model, X_train, y_train, loss_function := nn.CrossEntropyLoss())",
				"# %%",
				"# 모델 저장 및 불러오기",
				"torch.save(model.state_dict(), 'my_model.pth')",
				"model = MultiClassNetwork(",
				"    NUM_FEATURES=X.shape[1] if len(X.shape) != 1 else 1,",
				"    NUM_CLASSES=len(torch.unique(y)),",
				"    HIDDEN_FEATURES=HIDDEN_FEATURES,",
				")",
				"model.load_state_dict(torch.load('my_model.pth'))",
				"# %%",
				"# 예측",
				"from sklearn.metrics import accuracy_score",
				"",
				"with torch.no_grad():",
				"    y_test_hat_softmax = model(X_test)",
				"    y_test_hat = torch.max(y_test_hat_softmax.data, 1)  # 가장 확률 높은 클래스 선택",
				"print(accuracy_score(y_test, y_test_hat.indices))"
		],
		"description":"pytorch 분류기 기본 코드입니다."
	},
	"moviepy_1_user_code_snippet":{
		"prefix":"moviepy_1_user_code_snippet",
		"body":[
				"from moviepy.editor import *",
				"",
				"filename = 'video.mp4'",
				"clip = VideoFileClip(filename)",
				"clip = clip.subclip(0, 5)  # 0~5초 구간만 남기기",
				"clip = clip.fx(vfx.speedx, 3)  # 3배속",
				"clip.write_videofile('result_mp4.mp4')",
				"clip.ipython_display()"
		],
		"description":"moviepy 영상 자르기, 배속 코드입니다."
	},
	"pathlib_1_download_user_code_snippet":{
		"prefix":"pathlib_1_download_user_code_snippet",
		"body":[
			"from pathlib import Path",
			"import requests",
			"image_url = 'https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png'",
			"filename = 'result.png'",
			"Path(filename).write_bytes(requests.get(image_url).content)"
		],
		"description":"pathlib 활용한 간소화된 다운로드 코드입니다."
	},
	"pytorch_3_image_classfication_basic_user_code_snippet":{
		"prefix":"pytorch_3_image_classfication_basic_user_code_snippet",
		"body":[
				"# %%",
				"# 패키지 불러오기",
				"import torch",
				"import torch.nn as nn",
				"from torch.utils.data import Dataset, DataLoader",
				"from sklearn.model_selection import train_test_split",
				"",
				"",
				"# 데이터셋",
				"class MyDataset(Dataset):",
				"    def __init__(self, X, y):",
				"        self.X = X",
				"        self.y = y",
				"",
				"    def __len__(self):",
				"        return len(self.X)",
				"",
				"    def __getitem__(self, idx):",
				"        return self.X[idx], self.y[idx]",
				"",
				"",
				"# 훈련 메서드",
				"def train(model, X_train, y_train, loss_function):",
				"    train_loader = DataLoader(",
				"        dataset=MyDataset(X_train, y_train), batch_size=BATCH_SIZE",
				"    )",
				"    optimizer = torch.optim.Adam(model.parameters())",
				"    for epoch in range(EPOCHS):",
				"        for X, y in train_loader:",
				"            optimizer.zero_grad()",
				"            loss = loss_function(model(X), y)",
				"            loss.backward()",
				"            optimizer.step()",
				"",
				"        # print loss",
				"        if epoch % 100 == 0:",
				"            print(f'Epoch {epoch}, Loss: {loss.data}')",
				"    return model",
				"",
				"",
				"# 이 위까지는 공통 활용 코드로 수정 불필요",
				"###########################################################################################",
				"# %%",
				"# 하이퍼파라미터",
				"BATCH_SIZE = 4",
				"HIDDEN_FEATURES = 6",
				"LEARNING_RATE = 0.02",
				"EPOCHS = 10",
				"",
				"# %%",
				"# 데이터 준비",
				"import torchvision",
				"import torchvision.transforms as transforms",
				"import numpy as np",
				"",
				"transform = transforms.Compose(",
				"    [",
				"        transforms.Resize(32),",
				"        transforms.Grayscale(num_output_channels=1),",
				"        transforms.ToTensor(),",
				"        transforms.Normalize((0.5,), (0.5,)),",
				"    ]",
				")",
				"trainset = torchvision.datasets.ImageFolder(root='data/train', transform=transform)",
				"X_train = [data[0] for data in trainset]",
				"y_train = np.array(trainset.targets).astype(float)  # nn.BCELoss()의 y 값은 실수형이어야 함.",
				"testset = torchvision.datasets.ImageFolder(root='data/test', transform=transform)",
				"X_test = [data[0] for data in testset]",
				"y_test = np.array(testset.targets).astype(float)  # nn.BCELoss()의 y 값은 실수형이어야 함.",
				"",
				"",
				"# %%",
				"# 모델 선언",
				"class ImageClassificationNet(nn.Module):",
				"    def __init__(self) -&gt; None:",
				"        super().__init__()",
				"        self.conv1 = nn.Conv2d(1, 6, 3)",
				"        self.pool = nn.MaxPool2d(2, 2)",
				"        self.conv2 = nn.Conv2d(6, 16, 3)",
				"        self.fc1 = nn.Linear(16 * 6 * 6, 128)",
				"        self.fc2 = nn.Linear(128, 64)",
				"        self.fc3 = nn.Linear(64, 1)",
				"        self.relu = nn.ReLU()",
				"        self.sigmoid = nn.Sigmoid()",
				"",
				"    def forward(self, x):",
				"        x = self.conv1(x)",
				"        x = self.relu(x)",
				"        x = self.pool(x)",
				"        x = self.conv2(x)",
				"        x = self.relu(x)",
				"        x = self.pool(x)",
				"        x = torch.flatten(x, 1)",
				"        x = self.fc1(x)",
				"        x = self.relu(x)",
				"        x = self.fc2(x)",
				"        x = self.relu(x)",
				"        x = self.fc3(x)",
				"        x = self.sigmoid(x)",
				"        return x.squeeze().double()",
				"",
				"",
				"model = ImageClassificationNet()",
				"",
				"# %%",
				"# 학습",
				"train(model, X_train, y_train, loss_function := nn.BCELoss())",
				"# %%",
				"# 모델 저장 및 불러오기",
				"torch.save(model.state_dict(), 'my_model.pth')",
				"model = ImageClassificationNet()",
				"model.load_state_dict(torch.load('my_model.pth'))",
				"",
				"# %%",
				"# 예측",
				"from sklearn.metrics import accuracy_score",
				"",
				"test_loader = DataLoader(dataset=MyDataset(X_test, y_test), batch_size=BATCH_SIZE)",
				"y_pred = []",
				"model.eval()",
				"with torch.no_grad():",
				"    for X, y in test_loader:",
				"        y_pred.extend(model(X).round())  # 이진 값으로 만들기 위해 반올림(round)",
				"",
				"score = accuracy_score(y_test, y_pred)",
				"print(f'Test score{accuracy_score}: {score * 100}%')"
		],
		"description":"이미지 분류 코드입니다."
	},
	"pytorch_4_loss_function_user_code_snippet":{
		"prefix":"pytorch_4_loss_function_user_code_snippet",
		"body":[
			"import pandas as pd",
			"pd.set_option('display.max_colwidth', None)",
			"pytorch_metadata = pd.DataFrame(columns=['모델','설명','출력층','손실함수', '스코어링','X예시', 'y예시'])",
			"pytorch_metadata.loc[len(pytorch_metadata)] = ['회귀', '회귀','nn.Linear()','nn.MSELoss()(x,y)', 'r2_score(x,y)','torch.FloatTensor([1,2,3])','torch.FloatTensor([4,5,6])',]",
			"pytorch_metadata.loc[len(pytorch_metadata)] = ['분류 - 이진', 'nn.BCEWithLogitsLoss() 쓰자. nn.Sigmoid() + nn.BCELoss() = nn.BCEWithLogitsLoss()임. 즉 nn.BCEWithLogitsLoss() 쓰면 코드가 간결해짐.','nn.Sigmoid()','nn.BCELoss()(x,y)', 'accuracy_score(x,y)','0,1만 됨 torch.FloatTensor([1,0,1])','0,1만 됨 torch.FloatTensor([1,1,1])']",
			"pytorch_metadata.loc[len(pytorch_metadata)] = ['분류 - 멀티클래스','CrossEntropyLoss는 출력에 nn.Softmax() 적용해줌. 즉 코드에 nn.Softmax() 넣을 필요 없음.', 'nn.Linear()','nn.CrossEntropyLoss()(x,y)', 'accuracy_score(x,y)','torch.FloatTensor([1,2,3])','torch.FloatTensor([4,5,6])']",
			"pytorch_metadata.loc[len(pytorch_metadata)] = ['분류 - 멀티레이블', 'WithLogits이므로 알아서 Sigmoid 연산 해 줌. 문제는, 스코어링 할 때는 sigmoid + round 안 쓰면 연산이 안 된다는 거임.','nn.Linear()','nn.BCEWithLogitsLoss()(x,y)', 'accuracy_score(y, nn.Sigmoid()(model(x)).round())','torch.FloatTensor([1,2,3])','torch.FloatTensor([4,5,6])']",
			"pytorch_metadata"
		],
		"description":"pytorch에서 모델별 사용하는 손실함수 및 스코어링 함수입니다."
	}
}